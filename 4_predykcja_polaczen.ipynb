{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39eb517",
   "metadata": {},
   "source": [
    "# \"Introduction to Graph Representation Learning\"\n",
    "## Szkoła letnia AI-Tech 2023\n",
    "### Autor: Piotr Bielak\n",
    "\n",
    "![Logotypy sponsorów](sponsors.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df44f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/graphml-lab-pwr/intro-to-graph-representation-learning-workshop/master/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b895ff9",
   "metadata": {},
   "source": [
    "## 8. Predykcja krawędzi\n",
    "\n",
    "W wielu przypadkach możemy założyć, że nie posiadamy pełnej informacji o strukturze grafu, tzn. nie obserwujemy w zbiorze wszystkich krawędzi, które w rzeczywistości istnieją w danym grafie. Możemy jednak wyuczyć model, który uzupełni brakujące krawędzie (ang. **link prediction**). \n",
    "\n",
    "Zbiór krawędzi grafu dzielimy na zbiór treningowy, walidacyjny oraz testowy. Krawędzie ze zbioru testowego *usuwamy z grafu*, aby były nieobserwowane w trakcie uczenia wektorów reprezentacji (analogicznie dla zbioru walidacyjnego).\n",
    "\n",
    "Na tym etapie możemy zauważyć pewnien problem – mamy tylko informację o istniejących w grafie krawędziach. Nie wiadomo jak wyuczyć model klasyfikatora? Potrzebowalibyśmy jeszcze informacji o krawędziach, które nie istnieją w grafie, wtedy możemy uznać istniejące krawędzie (przykłady pozytywne) jako klasę $1$, a nieistniejące (przykłady negatywne) jako klasę $0$. \n",
    "\n",
    "Dokładnie tak rozwiążemy nasz problem – każdej krawędzi w obecnym zbiorze treningowym i testowym przypisujemy klasę $1$. Następnie dla każdej krawędzi losujemy ze zbioru wszystkich możliwych krawędzi, taką która nie istnieje w danym grafie i przypisujemy jej klasę $0$ (ang. *balanced negative sampling*).\n",
    "\n",
    "Wybór odpowiednich negatywnych przypadków jest bardziej skomplikowany i istnieje wiele strategii losowania, jednak pozostaniemy przy najprostszym scenariuszu losując krawędź zgodnie z rozkładem jednostajnym (tzn. każdy wybór tak samo prawdopodobny)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07729261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d40674",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcfbf84",
   "metadata": {},
   "source": [
    "Jako zbioru do zadania predykcji krawędzi użyjemy zbioru **CiteSeer**, który podobnie jak Cora jest zbiorem cytowań między artykułami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a3510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "\n",
    "dataset = Planetoid(root=\"/tmp/CiteSeer/\", name=\"CiteSeer\")\n",
    "\n",
    "data = dataset[0]\n",
    "\n",
    "data = data.to(device)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318e2fa",
   "metadata": {},
   "source": [
    "Usuniemy niepotrzebne informacje ze zbioru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc3856",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data.y\n",
    "del data.train_mask\n",
    "del data.val_mask\n",
    "del data.test_mask\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98f6dd",
   "metadata": {},
   "source": [
    "Podzielmy teraz zbiór na podzbiór treningowy, waliacyjny i testowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "\n",
    "train_data, val_data, test_data = RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.4,\n",
    "    is_undirected=True,\n",
    "    add_negative_train_samples=False,\n",
    ")(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3be2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1827a5aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805439d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c0be6",
   "metadata": {},
   "source": [
    "**Uwaga:** Ustawiamy argument `add_negative_train_samples=False`, aby dla zbioru treningowego nie były losowane przykłady negatywne – będziemy je losować w każdej epoce treningowej."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edea434a",
   "metadata": {},
   "source": [
    "**Uwaga 2:** Atrybuty wierzchołków `x` oraz krawędzie `edge_index` będziemy używać do obliczenia wektorów reprezentacji wierzchołkow, natomiast krawędzie `edge_label_index` oraz ich etykiety `edge_label` (0/1) będziemy używać do uczenia modelu / walidacji modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6805eba5",
   "metadata": {},
   "source": [
    "Kolejnym zagadnieniem jest jak otrzymać wektor reprezentacji dla krawędzi, skoro założyliśmy, że korzystamy z wektorów dla wierzchołków? Tutaj również mamy wiele możliwości, jednak najpopularniejszym rozwiązaniem jest wykorzystanie jednej z następujących transformacji wektorów reprezentacji wierzchołków $z_{uv} = z_u \\circ z_v$, gdzie $\\circ: \\mathcal{V} \\times \\mathcal{V} \\to \\mathbb{R}^{d}$. Metody te zostały zaproponowane w pracy [Node2vec](https://arxiv.org/pdf/1607.00653.pdf) i są aplikowane na każdym elemencie wektora reprezentacji osobno (ang. *element-wise*):\n",
    "\n",
    "| Nazwa | Wzór  |\n",
    "|-------|-------|\n",
    "| Średnia  | $$ z_{uv} = \\frac{z_u + z_v}{2}$$ |\n",
    "| Hadamard | $$ z_{uv} = z_u * z_v$$ |\n",
    "| L1       | $$ z_{uv} = |z_u - z_v|$$ |\n",
    "| L2       | $$ z_{uv} = |z_u - z_v|^2$$ |\n",
    "\n",
    "Innym podejściem może być konkatenacja wektorów, przy czym wtedy zwiększa się wymiarowość wyjściowa wektorów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class ToEdgeEmb(nn.Module):\n",
    "    \n",
    "    def __init__(self, node_dim: int):\n",
    "        super().__init__()\n",
    "        self.node_dim = node_dim\n",
    "    \n",
    "    @property\n",
    "    def output_dim(self) -> int:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def forward(self, z: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "\n",
    "class ToEdgeEmbMean(ToEdgeEmb):\n",
    "    \n",
    "    @property\n",
    "    def output_dim(self) -> int:\n",
    "        return self.node_dim\n",
    "    \n",
    "    def forward(self, z: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
    "        return (z[edge_index[0]] + z[edge_index[1]]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2156b32",
   "metadata": {},
   "source": [
    "Utwórzmy teraz model do uczenia reprezentacji krawędzi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35561441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, gnn: nn.Module, to_edge_emb: ToEdgeEmb):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gnn = gnn\n",
    "        self.to_edge_emb = to_edge_emb\n",
    "        self.clf_head = nn.Linear(to_edge_emb.output_dim, 1)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor):\n",
    "        return self.gnn(x=x, edge_index=edge_index)\n",
    "    \n",
    "    def score_edges(\n",
    "        self,\n",
    "        z: torch.Tensor,\n",
    "        edge_label_index: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        z_edge = self.to_edge_emb(z, edge_label_index)\n",
    "        return self.clf_head(z_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b23851",
   "metadata": {},
   "source": [
    "Korzystając ze standardowej pętli uczenia i funkcji binarnej entropii krzyżowej możemy wyuczyć powyższy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d836a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.nn import functional as F\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from tqdm.auto import trange\n",
    "\n",
    "\n",
    "def train(model: nn.Module, num_epochs: int):\n",
    "    losses = {\"train\": []}\n",
    "    aucs = {\"train\": [], \"val\": [], \"test\": []}\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=1e-3,\n",
    "        weight_decay=5e-4,\n",
    "    )\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in trange(num_epochs, desc=\"Epochs\"):\n",
    "        # Train\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        z = model(train_data.x, train_data.edge_index)\n",
    "        \n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=train_data.edge_index, \n",
    "            num_nodes=train_data.num_nodes,\n",
    "            num_neg_samples=train_data.edge_label_index.size(1), \n",
    "            method=\"sparse\",\n",
    "        )\n",
    "\n",
    "        edge_label_index = torch.cat(\n",
    "            [train_data.edge_label_index, neg_edge_index],\n",
    "            dim=-1,\n",
    "        )\n",
    "        edge_label = torch.cat(\n",
    "            [\n",
    "                train_data.edge_label,\n",
    "                train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "            ], \n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "        edge_scores = model.score_edges(z, edge_label_index).view(-1)\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            input=edge_scores,\n",
    "            target=edge_label,\n",
    "        )\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Log\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            z = model(data.x, data.edge_index)\n",
    "            \n",
    "            val_edge_scores = (\n",
    "                model\n",
    "                .score_edges(z, val_data.edge_label_index)\n",
    "                .view(-1)\n",
    "                .sigmoid()\n",
    "                .cpu()\n",
    "            )\n",
    "            test_edge_scores = (\n",
    "                model\n",
    "                .score_edges(z, test_data.edge_label_index)\n",
    "                .view(-1)\n",
    "                .sigmoid()\n",
    "                .cpu()\n",
    "            )\n",
    "                \n",
    "        losses[\"train\"].append(loss.detach().cpu())\n",
    "        aucs[\"train\"].append(roc_auc_score(\n",
    "            y_true=edge_label.cpu(),\n",
    "            y_score=edge_scores.view(-1).sigmoid().cpu().detach(),\n",
    "        ))\n",
    "        aucs[\"val\"].append(roc_auc_score(\n",
    "            y_true=val_data.edge_label.cpu(),\n",
    "            y_score=val_edge_scores,\n",
    "        ))\n",
    "        aucs[\"test\"].append(roc_auc_score(\n",
    "            y_true=test_data.edge_label.cpu(),\n",
    "            y_score=test_edge_scores,\n",
    "        ))\n",
    "        \n",
    "    # Visualize metrics\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    axs = axs.ravel()\n",
    "    axs[0].plot(range(num_epochs), losses[\"train\"], label=\"Train\")\n",
    "    axs[0].set(title=\"Loss\")\n",
    "    axs[0].legend()\n",
    "    \n",
    "    axs[1].plot(range(num_epochs), aucs[\"train\"], label=\"Train\")\n",
    "    axs[1].plot(range(num_epochs), aucs[\"val\"], label=\"Val\")\n",
    "    axs[1].plot(range(num_epochs), aucs[\"test\"], label=\"Test\")\n",
    "    best_val_auc = max(aucs[\"val\"])\n",
    "    best_idx = aucs[\"val\"].index(best_val_auc)\n",
    "    best_test_auc = aucs[\"test\"][best_idx]\n",
    "    \n",
    "    axs[1].set(title=f\"AUC (best val: {best_val_auc:.4f}, test: {best_test_auc:.4f})\")\n",
    "    axs[1].legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCN\n",
    "\n",
    "\n",
    "train(\n",
    "    model=LinkPredictionModel(\n",
    "        gnn=GCN(\n",
    "            in_channels=dataset.num_node_features,\n",
    "            hidden_channels=256,\n",
    "            out_channels=128,\n",
    "            num_layers=2,\n",
    "            act=\"relu\",\n",
    "        ),\n",
    "        to_edge_emb=ToEdgeEmbMean(128),\n",
    "    ),\n",
    "    num_epochs=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f126b",
   "metadata": {},
   "source": [
    "## Zadanie (10 min)\n",
    "\n",
    "## Z.3. Implementacja innych operatorów osadzeń krawędziowych\n",
    "\n",
    "Zaimplementuj pozostałe operatory do uzyskiwania reprezentacji krawędzi (z powższej tabelki oraz operator konkatenacji). Porównaj jakość działania przy zastosowaniu sieci GCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wpisz rozwiązania tutaj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e853a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
